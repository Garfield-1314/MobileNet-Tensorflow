# Jupyter Notebook - ä»£ç 

# å¯¼å…¥å¿…è¦çš„åº“
import matplotlib.pyplot as plt
import numpy as np
import os,shutil
import tensorflow as tf
import seaborn as sns
from tqdm import tqdm
import datetime

# è®¾å®šæ—¥å¿—çº§åˆ«
tf.get_logger().setLevel('ERROR')

# ğŸ”¹ è¶…å‚æ•°
IMG_SIZE = (96, 96)
AUTOTUNE = tf.data.AUTOTUNE
IMG_SHAPE = IMG_SIZE + (3,)

# æ£€æŸ¥ç¼“å­˜ç›®å½•æ˜¯å¦å­˜åœ¨å¹¶åˆ é™¤
folder = 'cache'

if os.path.exists(folder) and os.path.isdir(folder):
    try:
        shutil.rmtree(folder)
        print(f"æˆåŠŸåˆ é™¤ç›®å½•: {folder}")
    except Exception as e:
        print(f"åˆ é™¤å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯: {e}")
else:
    print(f"ç›®å½• '{folder}' ä¸å­˜åœ¨")
    
BATCH_SIZE = 32

# ğŸ”¹ æ•°æ®é›†è·¯å¾„
cache_dir = os.path.join('cache')
os.makedirs(cache_dir, exist_ok=True)

base_dir = '../data'
train_dir = os.path.join(base_dir, 'object')
valid_dir = os.path.join(base_dir, 'object')

# ğŸ”¹ åŠ è½½æ•°æ®é›†
train_dataset_raw = tf.keras.preprocessing.image_dataset_from_directory(
    train_dir, 
    validation_split=0.2, 
    subset="training", 
    seed=12,
    batch_size=BATCH_SIZE, 
    image_size=IMG_SIZE)

validation_dataset_raw = tf.keras.preprocessing.image_dataset_from_directory(
    valid_dir, 
    validation_split=0.2, 
    subset="validation", 
    seed=12,
    batch_size=BATCH_SIZE, 
    image_size=IMG_SIZE)

class_names = train_dataset_raw.class_names
print("Class Names:", class_names)

# ç”Ÿæˆ labels.txt æ–‡ä»¶
labels_path = os.path.join(cache_dir, 'labels.txt')  # ä¿å­˜åˆ°ç¼“å­˜ç›®å½•
with open(labels_path, 'w') as f:
    for class_name in class_names:
        f.write(f"{class_name}\n")

print(f"æ ‡ç­¾æ–‡ä»¶å·²ç”Ÿæˆ: {labels_path}")

# é¢„å¤„ç†å‡½æ•°ï¼ˆæ·»åŠ å¢å¼ºï¼‰
def preprocess_image(image, label):
    return image, label

# åŠ è½½æ•°æ®é›†
train_dataset = (train_dataset_raw
                 .map(preprocess_image, num_parallel_calls=AUTOTUNE)
                 .cache(os.path.join(cache_dir, 'train_cache1')) # ç¼“å­˜åˆ°æ–‡ä»¶
                 .shuffle(1000)
                 .prefetch(AUTOTUNE))

validation_dataset = (validation_dataset_raw
                      .map(preprocess_image, num_parallel_calls=AUTOTUNE)
                      .cache(os.path.join(cache_dir, 'val_cache1'))
                      .prefetch(AUTOTUNE))

# ğŸ”¹ æ„å»ºæ¨¡å‹

base_model = tf.keras.applications.MobileNetV2(
    input_shape=IMG_SHAPE, 
    include_top=False, 
    pooling = 'avg', 
    alpha=0.35, 
    weights='imagenet')

model = tf.keras.Sequential([
    tf.keras.layers.Rescaling(1./255),
    base_model,
    tf.keras.layers.Dropout(0.1),
    tf.keras.layers.Dense(len(class_names), activation='softmax')
])
model.build((None, 96, 96, 3))
model.summary()
# ç¼–è¯‘æ¨¡å‹

lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.00001, decay_steps=len(train_dataset), decay_rate=0.99, staircase=True)

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
              metrics=['accuracy'])

early_stopping = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)

history = model.fit(train_dataset,
                    validation_data=validation_dataset,
                    epochs=100, 
                    callbacks=[early_stopping]
                    ) 

# ğŸ”¹ ç›´æ¥å¯¼å‡ºä¸ºTFLiteæ ¼å¼ (æ— éœ€ä¿å­˜H5)
def representative_dataset():
    # ä»éªŒè¯é›†å–500ä¸ªæ‰¹æ¬¡ä½œä¸ºé‡åŒ–æ ¡å‡†æ•°æ®
    for images, _ in tqdm(validation_dataset.take(500), desc="Calibration"):
        yield [tf.cast(images, tf.float32)]  # è¾“å…¥éœ€ä¸ºæµ®ç‚¹å‹

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8   # è¾“å…¥ä¸ºuint8 (0-255)
converter.inference_output_type = tf.uint8  # è¾“å‡ºä¸ºuint8ç±»åˆ«ç´¢å¼•

tflite_model = converter.convert()

output_dir = './model/obj'
os.makedirs(output_dir, exist_ok=True)  # è‡ªåŠ¨åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
# ä¿å­˜å¸¦æ—¶é—´æˆ³çš„TFLiteæ¨¡å‹
timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M")
output_path = f'./model/obj/obj_model_{timestamp}.tflite'
with open(output_path, 'wb') as f:
    f.write(tflite_model)

print(f"TFLiteæ¨¡å‹å·²ä¿å­˜è‡³: {output_path}")

target_dir = "model"
# ç›´æ¥åŒ¹é…å½“å‰ç›®å½•ä¸‹çš„ .h5 æ–‡ä»¶
for file in os.listdir(target_dir):
    if file.endswith(".h5"):
        file_path = os.path.join(target_dir, file)
        try:
            os.remove(file_path)
            print(f"å·²åˆ é™¤: {file_path}")
        except Exception as e:
            print(f"åˆ é™¤å¤±è´¥ [{file_path}]: {e}")
from sklearn.metrics import confusion_matrix
# æ··æ·†çŸ©é˜µ
y_pred = np.argmax(model.predict(validation_dataset), axis=1)
y_true = np.concatenate([labels.numpy() for _, labels in validation_dataset])

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap="Blues", fmt="d", 
            xticklabels=class_names, yticklabels=class_names)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()
from lib import polt_improved

stage_names = ["history"]
history_list = [history]
polt_improved.plot_combined_curves_improved(history_list)